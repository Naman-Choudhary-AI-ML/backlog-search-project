# SpotLight Configuration
# Central configuration for all experiments and components

# Data paths
data:
  backlog_items: "evaluation/synthetic_data/synthetic_backlog_items.csv"
  test_queries: "evaluation/synthetic_data/test_queries_with_relevance.csv"
  embeddings_cache: ".cache/embeddings/"

# Search system parameters
search:
  # BM25 parameters (optimized via grid search)
  bm25:
    k1: 1.2  # Term frequency saturation parameter
    b: 0.75  # Document length normalization

  # Semantic search parameters
  semantic:
    model_name: "all-mpnet-base-v2"  # Sentence transformer model
    pooling: "max"  # Pooling strategy (max, mean, cls)
    chunk_size: 100  # Chunk size for long documents
    device: "cpu"  # Device for inference (cpu, cuda)

  # Hybrid fusion weights (optimized via grid search)
  fusion:
    bm25_weight: 0.4  # Weight for BM25 scores
    semantic_weight: 0.6  # Weight for semantic scores

  # Retrieval parameters
  retrieval:
    top_k: 50  # Number of candidates to retrieve
    final_k: 10  # Number of final results to return

# Cross-encoder reranking
cross_encoder:
  enabled: false  # Enable/disable cross-encoder reranking
  model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  batch_size: 16

# FAISS configuration
faiss:
  enabled: false  # Enable/disable FAISS
  index_type: "HNSW"  # Index type (FLAT, HNSW, IVF)
  hnsw_m: 32  # HNSW parameter: number of connections
  use_gpu: false

# LLM integration
llm:
  # Query expansion
  query_expansion:
    enabled: false  # RECOMMENDED: Keep disabled (degrades performance)
    model: "gpt-4-turbo"
    max_tokens: 200
    temperature: 0.7

  # RAG summarization
  rag:
    enabled: true  # Enable as optional feature
    model: "gpt-4-turbo"
    max_tokens: 300
    temperature: 0.5
    cache_ttl: 86400  # Cache TTL in seconds (24 hours)

  # Duplicate detection
  duplicate_detection:
    enabled: true
    model: "gpt-4-turbo"
    cosine_threshold: 0.85  # Only classify pairs above this threshold
    confidence_threshold: 0.8  # Minimum confidence to mark as duplicate

# Evaluation metrics
metrics:
  primary: "ndcg@10"  # Primary metric for optimization
  k_values: [5, 10, 20]  # k values for NDCG, Precision, Recall
  relevance_threshold: 1  # Minimum relevance score to consider relevant

# MLflow tracking
mlflow:
  experiment_name: "spotlight_search"
  tracking_uri: "mlruns"

# Privacy & compliance
privacy:
  anonymize_data: true  # Anonymize data before sending to LLM
  pii_patterns:
    - '\b\d{3}-\d{2}-\d{4}\b'  # SSN
    - '\b[A-Z]{2}\d{6}\b'  # Medical Record Number
    - '\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'  # IP addresses
    - 'v?\d+\.\d+\.\d+'  # Version numbers
    - 'https?://\S+'  # URLs

# Production settings
production:
  azure_openai:
    enabled: false  # Use Azure OpenAI for HIPAA compliance
    endpoint: ""  # Azure endpoint URL
    api_version: "2024-02-01"
    deployment_name: "gpt-4-turbo"

  caching:
    enabled: true
    backend: "redis"  # redis, memory, disk
    ttl: 3600  # Default TTL in seconds

  monitoring:
    log_level: "INFO"
    metrics_enabled: true
    alert_on_errors: true

# Development settings
development:
  debug: false
  cache_embeddings: true
  verbose_logging: false
